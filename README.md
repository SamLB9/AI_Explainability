# AI_Explainability
How can Machine Learning models be explained?

Artificial Intelligence (AI) makes it possible to harness huge volumes of data to perform complex tasks, usually very efficiently. However, AI models, and more specifically Machine Learning and even Deep Learning models, are often compared to "black boxes" due to their opaque operation, not necessarily understandable by humans. The complexity of these models is therefore a strength, as it enables us to respond to problems better than with simpler models, but it is also a weakness, as it makes them difficult to interpret. However, in certain critical fields such as medical diagnostics or autonomous driving, where human lives may be at stake, control and understanding of the decision-making mechanisms of these models is essential.

In concrete terms, explicability is a field of machine learning that aims to justify as precisely as possible a result given by a model. Explainability is developing remarkably well. Research in this field is very active, and companies are investing more and more in these issues.

AI explicability or interpretability aims to make the operation and results of models more intelligible and transparent to humans, without compromising on performance.
However, the difficulty today is that the more precise the models, the less explicable they become. So we're looking for a compromise. Even if for many data scientists, precision seems to be the supreme indicator of model quality, it's important to understand that it isn't everything. In deep learning, for example, explaining models is very difficult. Finding an algorithm as efficient as deep learning that is also 100% explainable is (for the moment?) utopian.

This need for explicability concerns different players, each with their own motivations. Firstly, for the Data Scientist who develops the model, a better understanding can help correct certain problems and improve the model. On the business side, explainability can be a means of assessing how well the model matches the company's strategy and objectives. Explanability can also be used to test the model's robustness, reliability and potential impact on customers. Finally, it can enable the customer who would be the object of a decision by a system based on an AI model to be informed of the impact of this decision and the potential actions possible to modify it.

![image](https://github.com/SamLB9/AI_Explainability/assets/106078401/08a09646-078c-4e6b-b175-3af1c75b029f)

In certain fields, such as health or law, the use of machine learning models that cannot be explained raises ethical questions and can prove dangerous. This aspect should be much more closely regulated. It could be interesting to create a text similar to the RGPD, but for explicability, which is an issue at least as sensitive as user data protection.

